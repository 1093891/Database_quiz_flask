id,type,difficulty,question,options,correct_answer,explanation
la_q1,mcq,hard,"For a discrete dynamical system $x_{k+1}=Ax_{k}$, if A has eigenvalues $\lambda_1, ..., \lambda_n$ and corresponding eigenvectors $v_1, ..., v_n$, and $|\lambda_1| > |\lambda_2| \geq ... \geq |\lambda_n|$, what is the long-term behavior of $x_k$ if $x_0$ is not a multiple of $v_1$?", "Converges to $v_1$ if $c_1 \neq 0$ and $|\lambda_1| = 1$.|Converges to 0 if all $|\lambda_i| < 1$.|Tends to grow in the direction of $v_1$ if $|\lambda_1| > 1$.|Oscillates if any eigenvalue is negative.",2,"If the largest eigenvalue in magnitude, $|\lambda_1|$, is greater than 1, and the initial vector $x_0$ has a non-zero component $c_1$ in the direction of $v_1$, then $x_k$ will tend to grow primarily in the direction of $v_1$. The formula $x_k=c_1(\lambda_1)^k v_1 + ... + c_n(\lambda_n)^k v_n$ shows that the term with the largest magnitude eigenvalue dominates as k approaches infinity."
la_q2,true_false,hard,"If the origin is a saddle point of a dynamical system $x_{k+1}=Ax_{k}$, it implies that all trajectories tend away from 0.",,false,"False. If the origin is a saddle point, some trajectories tend away from 0 (corresponding to eigenvalues with magnitude > 1) and some tend toward 0 (corresponding to eigenvalues with magnitude < 1)."
la_q3,drag_drop,hard,"Match the dynamical system behavior with the condition on eigenvalues.","drag1:Attractor|drag2:Repeller|drag3:Saddle Point;drop1:All eigenvalues have magnitude < 1.|drop2:All eigenvalues have magnitude > 1.|drop3:Some eigenvalues have magnitude > 1, and some have magnitude < 1.;drag1:drop1|drag2:drop2|drag3:drop3","","An attractor means all trajectories tend towards 0, which happens when all eigenvalues have magnitude < 1. A repeller means all trajectories tend away from 0, when all eigenvalues have magnitude > 1. A saddle point implies some tend away and some tend towards 0, hence eigenvalues both >1 and <1 in magnitude."
la_q4,mcq,hard,"Given a matrix A with eigenvalues 2 and 0.5, and corresponding eigenvectors $v_1=[1,0]^T$ and $v_2=[0,1]^T$. If $x_0 = [2, 1]^T$, what happens to $x_k$ as $k \rightarrow \infty$?", "It tends to the zero vector.|It tends to infinity along the $x_2$-axis.|It tends to infinity along the $x_1$-axis.|It oscillates around the origin.",2,"The solution is $x_k = c_1 2^k v_1 + c_2 (0.5)^k v_2$. As $k \rightarrow \infty$, the term $c_2 (0.5)^k v_2$ approaches zero, while the term $c_1 2^k v_1$ grows indefinitely. Since $x_0 = [2,1]^T = 2v_1 + 1v_2$, $c_1=2 \neq 0$. Thus, $x_k$ tends to infinity along the direction of $v_1$, which is the $x_1$-axis."
la_q5,true_false,hard,"The characteristic equation of an $n \times n$ matrix A is given by $A - \lambda I = 0$.",,false,"False. The characteristic equation is given by $|A - \lambda I| = 0$, where the determinant of the matrix $(A - \lambda I)$ is set to zero, not the matrix itself."
la_q6,mcq,hard,"If A is an $n \times n$ matrix and $\lambda$ is an eigenvalue of A, the set of all eigenvectors corresponding to $\lambda$, together with the zero vector, forms what is called the:", "Row space of A.|Column space of A.|Null space of A.|Eigenspace of $\lambda$.",3,"The set of all eigenvectors corresponding to an eigenvalue $\lambda$, combined with the zero vector, forms a subspace called the eigenspace of $\lambda$. This is equivalent to the null space of the matrix $(A - \lambda I)$."
la_q7,drag_drop,hard,"Match the condition for diagonalizability with its corresponding definition.","drag1:A is diagonalizable if...|drag2:A has n distinct eigenvalues then...;drop1:...it is similar to a diagonal matrix.|drop2:...A is diagonalizable.;drag1:drop1|drag2:drop2","","A matrix A is diagonalizable if it is similar to a diagonal matrix ($A = PDP^{-1}$). A sufficient, but not necessary, condition for diagonalizability is that if A has n distinct eigenvalues, then it is diagonalizable."
la_q8,mcq,hard,"If matrices A and B are similar ($P^{-1}AP=B$), which of the following properties do they NOT necessarily share?", "Same eigenvalues.|Same determinant.|Same trace.|Same eigenvectors.",3,"Similar matrices share the same eigenvalues, determinant, and trace. However, they do not necessarily share the same eigenvectors. The eigenvectors of B are $P^{-1}$ times the eigenvectors of A."
la_q9,true_false,hard,"A matrix A is diagonalizable if and only if it has $n$ linearly independent eigenvectors.",,true,"True. This is the core Diagonalization Theorem. An $n \times n$ matrix A is diagonalizable if and only if there is a basis of $\mathbb{R}^n$ consisting of eigenvectors of A, which implies having n linearly independent eigenvectors."
la_q10,mcq,hard,"If A is a diagonalizable matrix such that $A=PDP^{-1}$, then $A^k$ can be computed as:", "$P^{-1}D^kP$|$PD^kP^{-1}$|$P^{-1}DP^k$|$D^kP^{-1}P$",1,"If A is diagonalizable with $A=PDP^{-1}$, then $A^k = (PDP^{-1})(PDP^{-1})...(PDP^{-1}) = PD(P^{-1}P)D(P^{-1}P)...DP^{-1} = PD^kP^{-1}$. This simplifies the computation of matrix powers significantly."
la_q11,true_false,hard,"An $n \times n$ matrix A is invertible if and only if all eigenvalues of A are equal to zero.",,false,"False. A matrix A is invertible if and only if all eigenvalues of A are *not equal to* zero. If 0 is an eigenvalue, the matrix is singular (not invertible)."
la_q12,mcq,hard,"Given a linear transformation $T: V \rightarrow V$, a non-zero vector $x \in V$ is an eigenvector if $T(x) = \lambda x$ for some scalar $\lambda$. This $\lambda$ is called:", "The transformation coefficient.|The scaling factor.|The eigenvalue.|The nullity of T.",2,"The scalar $\lambda$ in the equation $T(x) = \lambda x$ is called an eigenvalue of the linear transformation T, and x is the corresponding eigenvector."
la_q13,true_false,hard,"For a linear transformation $T: V \rightarrow V$ and a basis $\mathcal{B}=\{b_1, ..., b_n\}$, the matrix M for T relative to $\mathcal{B}$ has columns formed by the coordinate vectors of the images of the basis vectors, i.e., $M = [[T(b_1)]_{\mathcal{B}} ... [T(b_n)]_{\mathcal{B}}]$.",,true,"True. This is the definition of the matrix representation of a linear transformation relative to a given basis."
la_q14,mcq,hard,"Which of the following is NOT a property that defines a vector space V?", "V is closed under vector addition.|V contains a zero vector.|Scalar multiplication is associative and distributive over vector addition.|The sum of any two vectors in V is always the zero vector.",3,"The sum of any two vectors in V being the zero vector is not a property of a vector space. A vector space requires closure under addition ($u+v \in V$), not that $u+v = 0$ for all $u, v \in V$."
la_q15,true_false,hard,"The set of all polynomials of degree less than or equal to $n$, denoted as $P_n$, forms a vector space.",,true,"True. $P_n$ satisfies all ten vector space axioms under standard polynomial addition and scalar multiplication."
la_q16,mcq,hard,"A subset H of a vector space V is a subspace if it satisfies which three properties?", "H is non-empty, H is closed under addition, H contains a basis.|The zero vector of V is in H, H is closed under addition, H is closed under scalar multiplication.|H is finite, H is closed under addition, H contains distinct vectors.|H is linearly independent, H spans V, H contains non-zero vectors.",1,"For H to be a subspace of V, it must contain the zero vector of V, be closed under vector addition, and be closed under scalar multiplication. These three properties are sufficient."
la_q17,true_false,hard,"The union of the first and third quadrants in the xy-plane (where $xy \ge 0$) is a subspace of $\mathbb{R}^2$.",,false,"False. While it contains the zero vector and is closed under scalar multiplication, it's not closed under addition. For example, $(1,0)$ and $(-1,0)$ are in the set, but their sum $(0,0)$ is, however, their sum is $(0,0)$, which is in the set. However, consider $(1,1)$ in Q1 and $(-1,-1)$ in Q3. Their sum $(0,0)$ is in the set. A better example: $(1,2)$ in Q1 and $(-3,-1)$ in Q3. Their sum is $(-2,1)$, which is in Q2, not the union of Q1 and Q3, and thus not in the specified set if we strictly define it as $xy \ge 0$. The provided source explicitly states 'find specific vectors u and v in W such that u+v is not in W. This is enough to show that W is not a vector space.' implying it's not a subspace."
la_q18,mcq,hard,"Which of the following sets is NOT a subspace of $R^3$?", "The x-axis, i.e., $\{(a,0,0) : a \in R\}$.|The set of all vectors of the form $(a,a^2,b)$.|The set of all vectors of the form $(a,a,a)$.|The set of all vectors whose components sum to zero.",1,"The set of all vectors of the form $(a,a^2,b)$ is not a subspace because it is not closed under addition. For example, if $(1,1,0)$ and $(2,4,0)$ are in the set, their sum $(3,5,0)$ is not of the form $(a,a^2,b)$ since $5 \neq 3^2$."
la_q19,true_false,hard,"The set of $7 \times 7$ singular matrices is a subspace of the vector space $M_{7,7}$ of $7 \times 7$ matrices.",,false,"False. The set of singular matrices is generally not a subspace because it's not closed under addition. For example, the sum of two singular matrices can be an invertible matrix. (e.g., identity matrix plus negative identity matrix which are both singular.)"
la_q20,drag_drop,hard,"Match the type of vector space to its standard dimension.","drag1:$\mathbb{R}^n$|drag2:$P_n$|drag3:$M_{m,n}$;drop1:n|drop2:n+1|drop3:mn;drag1:drop1|drag2:drop2|drag3:drop3","","The dimension of $\mathbb{R}^n$ is n. The dimension of $P_n$ (polynomials of degree up to n) is n+1. The dimension of $M_{m,n}$ (m x n matrices) is mn."
la_q21,mcq,hard,"A set of vectors $B=\{v_1, ..., v_k\}$ is a basis for a vector space V if:", "B is linearly dependent and spans V.|B is linearly independent and does not span V.|B is linearly independent and spans V.|B contains the zero vector.",2,"For a set of vectors to be a basis for a vector space V, it must satisfy two conditions: it must be linearly independent, and it must span V (i.e., every vector in V can be written as a linear combination of vectors in B)."
la_q22,true_false,hard,"If a set of vectors contains the zero vector, it cannot be a basis for any vector space.",,true,"True. A set containing the zero vector is always linearly dependent. For a set to be a basis, it must be linearly independent, thus it cannot contain the zero vector."
la_q23,mcq,hard,"The standard basis for $P_2(x)$ (polynomials of degree less than or equal to 2) is:", "$(1,x,x^2)$|$({1,t,t^2})$|$(0,x,x^2)$|$(1,1,1)$",1,"The standard basis for $P_n(x)$ is $\{1, x, x^2, ..., x^n\}$. So for $P_2(x)$, the standard basis is $\{1, x, x^2\}$ (or $\{1,t,t^2\}$ if using t as variable)."
la_q24,true_false,hard,"The dimension of $M_{2,3}(R)$ (the space of $2 \times 3$ matrices with real entries) is 5.",,false,"False. The dimension of $M_{m,n}$ is $mn$. So for $M_{2,3}(R)$, the dimension is $2 \times 3 = 6$."
la_q25,mcq,hard,"Suppose $\mathcal{B}=\{b_1, ..., b_n\}$ is a basis for V and x is in V. If $x=c_1b_1+\cdot\cdot\cdot+c_nb_n$, then the coordinate vector of x relative to $\mathcal{B}$ (or the $\mathcal{B}$-coordinate vector of x) is:", "$[x] = [c_1 ... c_n]$|$[x]_{\mathcal{B}} = [c_1 ... c_n]^T$|$x = P_{\mathcal{B}}[x]_{\mathcal{B}}$|$c_1 + ... + c_n$",1,"The coordinate vector of x relative to the basis $\mathcal{B}$ is a column vector in $\mathbb{R}^n$ consisting of the weights $c_1, ..., c_n$, denoted as $[x]_{\mathcal{B}} = [c_1 ... c_n]^T$."
la_q26,true_false,hard,"If $P_{\mathcal{B}}$ is the change-of-coordinates matrix from basis $\mathcal{B}$ to the standard basis, then $x = P_{\mathcal{B}}[x]_{\mathcal{B}}$.",,true,"True. This is the definition of the change-of-coordinates matrix from a basis $\mathcal{B}$ to the standard basis. The standard coordinates x can be obtained by multiplying the basis vectors in $P_{\mathcal{B}}$ by their corresponding $\mathcal{B}$-coordinates."
la_q27,mcq,hard,"Which of the following is an example of a Linear Time-Invariant (LTI) transformation from digital signal processing?", "A transformation where $T(\{x_k\}) = \{x_k^2\}$.|A transformation where $T(\{x_k\}) = \{x_k + k\}$.|A transformation where $T(\{x_k\}) = \{x_{k-1}\}$.|A transformation where $T(\{x_k\}) = \{|x_k|\}$.",2,"A shift operation, such as $T(\{x_k\}) = \{x_{k-1}\}$, is a classic example of a linear and time-invariant transformation. It satisfies linearity (additivity and homogeneity) and time-invariance (shifting the input signal results in an equally shifted output signal)."
la_q28,true_false,hard,"A moving average transformation, $M_m(\{x_k\}) = \{y_k\}$ where $y_k = \frac{1}{m}\sum_{j=k-m+1}^{k}x_k$, is a linear transformation.",,true,"True. The moving average operation is linear because it satisfies both the additivity property ($M_m(x+y) = M_m(x) + M_m(y)$) and the homogeneity property ($M_m(cx) = cM_m(x)$)."
la_q29,mcq,hard,"What does Rank(A) represent?", "The number of rows in A.|The number of columns in A.|The dimension of the row space of A.|The dimension of the null space of A.",2,"The rank of a matrix A is defined as the common dimension of its row space and column space. It's also equal to the number of pivot positions in an echelon form of A."
la_q30,true_false,hard,"Row operations on a matrix A alter its column space.",,true,"True. While row operations do not alter the row space or null space, they do change the column space itself. However, they preserve the linear dependence relations among the columns, meaning the dimension of the column space remains the same."
la_q31,drag_drop,hard,"Match the space with its definition relative to an $m \times n$ matrix A.","drag1:Row Space|drag2:Column Space|drag3:Null Space;drop1:Subspace of $\mathbb{R}^n$ spanned by the row vectors of A.|drop2:Subspace of $\mathbb{R}^m$ spanned by the column vectors of A.|drop3:Set of all solutions of the homogeneous system $Ax=0$.;drag1:drop1|drag2:drop2|drag3:drop3","","Row space is spanned by row vectors. Column space is spanned by column vectors. Null space is the set of solutions to $Ax=0$."
la_q32,mcq,hard,"If a $7 \times 9$ matrix A has a two-dimensional null space, what is the rank of A?", "9|7|2|7",3,"According to the Rank-Nullity Theorem, for an $m \times n$ matrix A, Rank(A) + Nullity(A) = n (number of columns). Here, n=9 and Nullity(A)=2, so Rank(A) + 2 = 9, which means Rank(A) = 7."
la_q33,true_false,hard,"Col A is implicitly defined, meaning you are given only a condition ($Ax=b$) that vectors in Col A must satisfy.",,false,"False. Col A is *explicitly* defined; you are told how to build vectors in Col A (they are linear combinations of the columns of A). Nul A is implicitly defined ($Ax=0$). "
la_q34,mcq,hard,"The kernel of a linear transformation $T: V \rightarrow W$ is defined as:", "The set of all vectors $u \in V$ such that $T(u)$ is a scalar multiple of $u$.|The set of all vectors $u \in W$ that are in the range of T.|The set of all vectors $u \in V$ such that $T(u) = \vec{0}$ (the zero vector in W).|The dimension of the range of T.",2,"The kernel of a linear transformation T is the set of all vectors in the domain V that map to the zero vector in the codomain W. It is equivalent to the null space for matrix transformations."
la_q35,true_false,hard,"The Invertible Matrix Theorem states that an $n \times n$ matrix A is invertible if and only if its rank is $n$ and its nullity is $0$.",,true,"True. The Invertible Matrix Theorem has many equivalent statements, including that A is invertible if and only if Rank(A)=n and Nullity(A)=0 (meaning Nul A = {0})."
la_q36,mcq,hard,"For a matrix A= $[\begin{smallmatrix} 4 & 2 \\ 0 & 3 \end{smallmatrix}]$, what are its eigenvalues?", "4 and 2|0 and 3|4 and 3|Cannot be determined without a characteristic polynomial",2,"For an upper triangular matrix, the eigenvalues are the entries on the main diagonal. So, for A, the eigenvalues are 4 and 3."
la_q37,true_false,hard,"If an $n \times n$ matrix has an eigenvalue of 0, then the matrix is invertible.",,false,"False. If an $n \times n$ matrix has an eigenvalue of 0, it means the determinant is 0, and thus the matrix is singular (not invertible)."
la_q38,mcq,hard,"Given an $n \times n$ matrix A, if A has $n$ distinct eigenvalues, then which of the following is true?", "A is not diagonalizable.|A is singular.|A is diagonalizable.|A is invertible if and only if n is odd.",2,"If an $n \times n$ matrix has $n$ distinct eigenvalues, then it is guaranteed to be diagonalizable."
la_q39,true_false,hard,"If $A=PDP^{-1}$, then $A^{-1} = P D^{-1} P^{-1}$ given that D is invertible.",,true,"True. If A is diagonalizable and D is invertible (meaning no eigenvalue is zero), then $A^{-1}$ can be computed as $P D^{-1} P^{-1}$."
la_q40,mcq,hard,"The sequence $\{s_k\} = \{cos(\frac{k\pi}{2})\}$ is an eigenvector of the shift linear transformation $D(\{x_k\}) = \{x_{k+2}\}$. What is its corresponding eigenvalue?", "1|0|-1|0.5",2,"If $D(\{s_k\}) = \{s_{k+2}\} = \{cos(\frac{(k+2)\pi}{2})\} = \{cos(\frac{k\pi}{2} + \pi)\} = \{-cos(\frac{k\pi}{2})\} = -\{s_k\}$. Thus, the eigenvalue is -1."
la_q41,true_false,hard,"The set $W = \{ (a,b,c) \in \mathbb{R}^3 : a=c \}$ is a subspace of $\mathbb{R}^3$ with dimension 2.",,true,"True. Any vector in W can be written as $(c,b,c) = c(1,0,1) + b(0,1,0)$. The vectors $\{(1,0,1), (0,1,0)\}$ are linearly independent and span W, forming a basis. Thus, the dimension of W is 2."
la_q42,mcq,hard,"What is the dimension of the subspace W of all symmetric matrices in $M_{2,2}$?", "1|2|3|4",2,"A symmetric $2 \times 2$ matrix has the form $[\begin{smallmatrix} a & b \\ b & c \end{smallmatrix}]$. This can be written as $a[\begin{smallmatrix} 1 & 0 \\ 0 & 0 \end{smallmatrix}] + b[\begin{smallmatrix} 0 & 1 \\ 1 & 0 \end{smallmatrix}] + c[\begin{smallmatrix} 0 & 0 \\ 0 & 1 \end{smallmatrix}]$. These three matrices form a basis for W, so its dimension is 3."
la_q43,true_false,hard,"If the number of vectors in a set is not equal to the dimension of the vector space V, then it cannot be a basis for V.",,true,"True. A basis for a vector space V must contain exactly dim(V) vectors."
la_q44,mcq,hard,"For an $m \times n$ matrix A, the dimension of the row space of A equals the dimension of the column space of A. This common dimension is called the:", "Nullity of A.|Trace of A.|Determinant of A.|Rank of A.",3,"The common dimension of the row space and column space of a matrix A is defined as the rank of A."
la_q45,true_false,hard,"The sum of the dimensions of the row space and the null space of an $m \times n$ matrix A equals the number of rows in A.",,false,"False. The Rank-Nullity Theorem states that the sum of the dimensions of the column space (or row space) and the null space of an $m \times n$ matrix A equals the number of *columns* (n) in A."
la_q46,mcq,hard,"Consider the dynamical system $x_{k+1}=Ax_{k}$ with $A=[\begin{smallmatrix} 0.8 & 0 \\ 0 & 0.64 \end{smallmatrix}]$. What is the eventual behavior of the system?", "Origin is a repeller.|Origin is a saddle point.|Origin is an attractor.|System oscillates without converging.",2,"The eigenvalues are 0.8 and 0.64. Since both eigenvalues have a magnitude less than 1 ($|0.8|<1$ and $|0.64|<1$), the origin is an attractor, meaning all trajectories tend towards 0."
la_q47,true_false,hard,"If an initial vector $x_0$ for a discrete dynamical system $x_{k+1}=Ax_{k}$ is a multiple of an eigenvector $v$ corresponding to an eigenvalue $\lambda$, then $x_k = \lambda^k x_0$.",,true,"True. If $x_0 = c v$, then $x_k = A^k x_0 = A^k (cv) = c A^k v = c \lambda^k v = \lambda^k (cv) = \lambda^k x_0$. This simplifies the behavior to simple scaling."
la_q48,mcq,hard,"Which of the following matrices is NOT diagonalizable?", "$A=[\begin{smallmatrix} 1 & 3 \\ 3 & 1 \end{smallmatrix}]$|$A=[\begin{smallmatrix} 1 & -1 & -1 \\ 0 & 1 & -2 \\ 0 & 1 & 4 \end{smallmatrix}]$|$A=[\begin{smallmatrix} 1 & 2 \\ 0 & 1 \end{smallmatrix}]$|$A=[\begin{smallmatrix} 1 & -1 & -1 \\ 1 & 3 & 1 \\ -3 & 1 & -1 \end{smallmatrix}]$",2,"The matrix $A=[\begin{smallmatrix} 1 & 2 \\ 0 & 1 \end{smallmatrix}]$ has a repeated eigenvalue of 1. When you find its eigenspace, you'll discover it only has one linearly independent eigenvector (e.g., $[1,0]^T$). Since it is a $2 \times 2$ matrix but only has 1 linearly independent eigenvector, it is not diagonalizable."
la_q49,true_false,hard,"For a linear transformation $T:P_2 \rightarrow P_2$ defined by differentiation ($T(a_0+a_1t+a_2t^2) = a_1+2a_2t$), the matrix M for T relative to the basis $\{1,t,t^2\}$ is $[\begin{smallmatrix} 0 & 1 & 0 \\ 0 & 0 & 2 \\ 0 & 0 & 0 \end{smallmatrix}]$.",,true,"True. The transformation maps: $T(1)=0 = 0\cdot1+0\cdot t+0\cdot t^2 \Rightarrow [T(1)]_{\mathcal{B}}=[0,0,0]^T$. $T(t)=1 = 1\cdot1+0\cdot t+0\cdot t^2 \Rightarrow [T(t)]_{\mathcal{B}}=[1,0,0]^T$. $T(t^2)=2t = 0\cdot1+2\cdot t+0\cdot t^2 \Rightarrow [T(t^2)]_{\mathcal{B}}=[0,2,0]^T$. The matrix M is formed by these column vectors."
la_q50,mcq,hard,"What is the nullity of an $8 \times 5$ matrix A if its null space is 2-dimensional?", "8|5|2|3",2,"The nullity of a matrix is defined as the dimension of its null space. If the null space is 2-dimensional, then the nullity is 2."
